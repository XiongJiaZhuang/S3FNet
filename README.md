# S3FNet: Spatial-Spectral Similarity-Guided Fusion Network for Pansharpening

- Code for the paper: "Spatial-Spectral Similarity-Guided Fusion Network for Pansharpening", IJCAI 2025.

# Method

## Overall Structure

![S3FNet](./readme_image/s3fnet.jpg#pic_center)
Overall structure of our S3FNet. It contains three key parts. PAN and LRMS images firstly pass through a shallow feature
extraction(SFE) layer. Next, the extracted features enter a multi-branch asymmetric encoder with spatial, spectral and
fusion branches. Finally, the features are processed through a multi-scale reconstruction decoder incorporated with a
well-designed cross-feature multi-head attention fusion block (CMAFB) to generate the HRMS image.

## CMAFB

![CMAFB](./readme_image/CMAFB.jpg#pic_center)

It takes the features generated by the three branches in the encoder as input and produces fused features using spatial
cross-attention (SpeCA), spectral cross-attention (SpaCA) mechanisms, and a locally-enhanced feed-forward layer
(LeFF).

# Experimental Results

- Quantitative evalutaion results on WV3, GF2, WV2 datasets of PanCollection.

![table_compare](./readme_image/table_compare.png#pic_center)

- Qualitative evalutaion results on the WV3 dataset of PanCollection.

![wv3_compare](./readme_image/wv3_compare.jpg#pic_center)

# Get Started

## Dataset

- Datasets for pansharpening: [PanCollection](https://github.com/liangjiandeng/PanCollection).

## Installation and Requirements

```shell
git clone https://github.com/XiongJiaZhuang/S3FNet.git
cd S3FNet
pip install -r requirements.txt
```

```shell
# train
python train_gf2.py
# test
python test_gf2.py
```

# Contact
Thank you very much for your interest in my work.
If you would like to get in touch, please feel free to reach me via:
- Email: xjz19980901@gmail.com
- WeChat: Scan the following QR code to connect.


<p align="center">
  <img src="./readme_image/wechat.png" alt="WeChat QR Code" width="150"/>
</p>

# References
- Siran Peng, Chenhao Guo, Xiao Wu, and Liang-Jian Deng. U2net: A general framework with spatial-spectral-integrated double u-net for image fusion. In ACM Multimedia 2023. [DOI](https://dl.acm.org/doi/10.1145/3581783.3612084)
- Zixiang Zhao, Haowen Bai, Jiangshe Zhang, Yulun Zhang, Shuang Xu, Zudi Lin, Radu Timofte, and Luc Van Gool. Cddfuse: Correlation-driven dual-branch feature decomposition for multi-modality image fusion. In CVPR 2023. [DOI](https://doi.org/10.1109/CVPR52729.2023.00572)

# Acknowledgements
- This code is partially inspired by the [U2Net](https://github.com/PSRben/U2Net) repository.
